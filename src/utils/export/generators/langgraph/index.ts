import { ExportResult } from '../../types';
import { BaseExportGenerator } from '../base';

/**
 * LangGraph Export Generator.
 * Generates a Python project with graph-based state machines.
 */
export class LangGraphGenerator extends BaseExportGenerator {
  generate(): ExportResult {
    // Validate first
    if (!this.validate()) {
      return this.buildResult();
    }

    // Generate project files
    this.addFile('README.md', this.generateReadme());
    this.addFile('pyproject.toml', this.generatePyProject());
    this.addFile('requirements.txt', this.generateRequirements());
    this.addFile('.env.example', this.generateEnvExample());

    // Generate Python source files
    this.addFile('src/__init__.py', '# LangGraph workflow package\n');
    this.addFile('src/main.py', this.generateMain());
    this.addFile('src/state.py', this.generateState());
    this.addFile('src/graph.py', this.generateGraph());

    // Generate node files for each agent
    this.generateAgentNodes();

    // Generate edge routing
    this.addFile('src/edges/__init__.py', '');
    this.addFile('src/edges/routing.py', this.generateRouting());

    // Generate prompts directory
    this.addFile('src/prompts/__init__.py', '');
    this.generatePromptFiles();

    return this.buildResult();
  }

  private generateReadme(): string {
    return `# ${this.config.name}

${this.config.description || 'LangGraph-based multi-agent workflow.'}

## Setup

\`\`\`bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # or venv\\Scripts\\activate on Windows

# Install dependencies
pip install -e .

# Set environment variables
cp .env.example .env
# Edit .env with your API keys
\`\`\`

## Usage

\`\`\`bash
# Run the workflow
python -m src.main "Your task or query here"

# With visualization
python -m src.main --visualize
\`\`\`

## Project Structure

\`\`\`
.
├── src/
│   ├── __init__.py
│   ├── main.py          # Entry point
│   ├── graph.py         # Graph definition
│   ├── state.py         # State schemas
│   ├── nodes/           # Agent node implementations
│   ├── edges/           # Routing logic
│   └── prompts/         # Agent prompts
├── tests/
├── pyproject.toml
└── requirements.txt
\`\`\`

---

*Generated by Visual Agent Builder on ${this.formatDate()}*
`;
  }

  private generatePyProject(): string {
    const name = this.slugify(this.config.name);
    return `[project]
name = "${name}"
version = "${this.config.version}"
description = "${this.config.description || 'LangGraph workflow'}"
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
    "langgraph>=0.2.0",
    "langchain>=0.2.0",
    "langchain-anthropic>=0.1.0",
    "langchain-openai>=0.1.0",
    "python-dotenv>=1.0.0",
    "pydantic>=2.0.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=8.0.0",
    "pytest-asyncio>=0.23.0",
    "black>=24.0.0",
    "ruff>=0.3.0",
    "mypy>=1.8.0",
]

[project.scripts]
run = "src.main:main"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.black]
line-length = 100

[tool.ruff]
line-length = 100
select = ["E", "F", "I", "N", "W"]
`;
  }

  private generateRequirements(): string {
    return `langgraph>=0.2.0
langchain>=0.2.0
langchain-anthropic>=0.1.0
langchain-openai>=0.1.0
python-dotenv>=1.0.0
pydantic>=2.0.0
`;
  }

  private generateEnvExample(): string {
    return `# Required
ANTHROPIC_API_KEY=your-anthropic-api-key

# Optional
OPENAI_API_KEY=your-openai-api-key

# Database (for checkpointing)
DATABASE_URL=sqlite:///./workflow.db
`;
  }

  private generateMain(): string {
    return `"""
Main entry point for ${this.config.name}.
Generated by Visual Agent Builder.
"""

from __future__ import annotations

import asyncio
import argparse
from dotenv import load_dotenv

from .graph import run_workflow, get_graph_mermaid


def main():
    """CLI entry point."""
    load_dotenv()

    parser = argparse.ArgumentParser(
        description="${this.config.description || 'LangGraph workflow'}"
    )
    parser.add_argument(
        "message",
        nargs="?",
        default="",
        help="Task or message to process"
    )
    parser.add_argument(
        "--visualize",
        action="store_true",
        help="Print graph visualization and exit"
    )
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="Enable verbose output"
    )

    args = parser.parse_args()

    if args.visualize:
        print(get_graph_mermaid())
        return 0

    if not args.message:
        print("Error: Please provide a message or use --visualize")
        return 1

    # Run workflow
    result = asyncio.run(run_workflow(args.message))

    # Print results
    if result.get("error"):
        print(f"Error: {result['error']}")
        return 1

    print("\\n=== Workflow Complete ===\\n")
    print(result.get("output", "No output"))

    return 0


if __name__ == "__main__":
    exit(main())
`;
  }

  private generateState(): string {
    // State schema type available for future customization
    // const schemaType = this.config.frameworkOptions.langgraph!.stateSchema;

    return `"""
State schema definitions for the workflow graph.
Generated by Visual Agent Builder.
"""

from __future__ import annotations

from typing import Annotated, Any, Literal, TypedDict
from pydantic import BaseModel, Field
from langgraph.graph.message import add_messages


# =============================================================================
# Message Types
# =============================================================================

class AgentMessage(BaseModel):
    """Structured message passed between agents."""

    sender: str = Field(description="Agent that sent the message")
    receiver: str = Field(description="Intended recipient agent")
    content: str = Field(description="Message content")
    metadata: dict[str, Any] = Field(default_factory=dict)


# =============================================================================
# Main Graph State
# =============================================================================

class WorkflowState(TypedDict):
    """
    Main state object passed through the graph.
    """

    # Message history (uses add_messages reducer)
    messages: Annotated[list, add_messages]

    # Current workflow phase
    phase: str

    # Active agent
    current_agent: str | None

    # Task/query being processed
    task: str | None

    # Results and outputs
    output: str | None

    # Error handling
    error: str | None
    retry_count: int


# =============================================================================
# Factory Functions
# =============================================================================

def create_initial_state(task: str) -> WorkflowState:
    """Create initial workflow state."""
    return WorkflowState(
        messages=[],
        phase="init",
        current_agent=None,
        task=task,
        output=None,
        error=None,
        retry_count=0,
    )
`;
  }

  private generateGraph(): string {
    const agents = this.getNodesByType('AGENT');
    const options = this.config.frameworkOptions.langgraph!;

    // Generate node imports
    const nodeImports = agents
      .map((a) => {
        const name = this.slugify(a.data.config?.name || a.data.label);
        return `from .nodes.${name} import run as ${name}_run`;
      })
      .join('\n');

    // Generate node additions
    const nodeAdditions = agents
      .map((a) => {
        const name = this.slugify(a.data.config?.name || a.data.label);
        return `    graph.add_node("${name}", ${name}_run)`;
      })
      .join('\n');

    // Generate edges (simplified - first agent to start, linear flow)
    const agentNames = agents.map((a) =>
      this.slugify(a.data.config?.name || a.data.label)
    );

    let edgeSetup = '';
    if (agentNames.length > 0) {
      edgeSetup = `    graph.add_edge(START, "${agentNames[0]}")`;
      for (let i = 0; i < agentNames.length - 1; i++) {
        edgeSetup += `\n    graph.add_edge("${agentNames[i]}", "${agentNames[i + 1]}")`;
      }
      if (agentNames.length > 0) {
        edgeSetup += `\n    graph.add_edge("${agentNames[agentNames.length - 1]}", END)`;
      }
    }

    return `"""
Main graph definition for ${this.config.name}.
Generated by Visual Agent Builder.
"""

from __future__ import annotations

from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import MemorySaver

from .state import WorkflowState, create_initial_state
${nodeImports}


# =============================================================================
# Graph Configuration
# =============================================================================

GRAPH_CONFIG = {
    "name": "${this.config.name}",
    "version": "${this.config.version}",
    "checkpointer": "${options.checkpointer}",
    "recursion_limit": ${options.recursionLimit},
}


# =============================================================================
# Graph Builder
# =============================================================================

def build_graph() -> StateGraph:
    """Build the main workflow graph."""

    graph = StateGraph(WorkflowState)

    # Add nodes
${nodeAdditions}

    # Add edges
${edgeSetup}

    return graph


# =============================================================================
# Graph Compilation
# =============================================================================

def compile_graph():
    """Compile the graph with checkpointing."""
    graph = build_graph()

    if GRAPH_CONFIG["checkpointer"] == "memory":
        memory = MemorySaver()
        return graph.compile(checkpointer=memory)
    else:
        return graph.compile()


# Compiled graph singleton
app = compile_graph()


async def run_workflow(task: str, session_id: str | None = None) -> dict:
    """Run the workflow with a given task."""
    import uuid

    session_id = session_id or str(uuid.uuid4())
    initial_state = create_initial_state(task)

    config = {"configurable": {"thread_id": session_id}}

    result = await app.ainvoke(initial_state, config)
    return result


def get_graph_mermaid() -> str:
    """Generate Mermaid diagram of the graph."""
    graph = build_graph()
    return graph.get_graph().draw_mermaid()
`;
  }

  private generateAgentNodes(): void {
    const agents = this.getNodesByType('AGENT');

    this.addFile('src/nodes/__init__.py', '');

    for (const agent of agents) {
      const name = this.slugify(agent.data.config?.name || agent.data.label);
      const config = agent.data.config || {};

      const content = `"""
${config.name || agent.data.label} node implementation.
Generated by Visual Agent Builder.
"""

from __future__ import annotations

from typing import Any
from langchain_anthropic import ChatAnthropic
from langchain_core.messages import HumanMessage, SystemMessage

from ..state import WorkflowState
from ..prompts.${name} import SYSTEM_PROMPT


# =============================================================================
# Agent Configuration
# =============================================================================

AGENT_CONFIG = {
    "name": "${name}",
    "role": "${config.role || 'solo'}",
    "model": {
        "provider": "${config.provider || 'anthropic'}",
        "name": "${config.model || 'claude-sonnet-4-20250514'}",
        "temperature": ${config.temperature ?? 0.7},
        "max_tokens": ${config.maxTokens || 4096},
    },
}


# =============================================================================
# Agent Implementation
# =============================================================================

def get_model() -> ChatAnthropic:
    """Initialize the language model."""
    return ChatAnthropic(
        model=AGENT_CONFIG["model"]["name"],
        temperature=AGENT_CONFIG["model"]["temperature"],
        max_tokens=AGENT_CONFIG["model"]["max_tokens"],
    )


async def run(state: WorkflowState) -> dict[str, Any]:
    """Execute the ${name} agent node."""

    model = get_model()
    task = state.get("task", "")

    messages = [
        SystemMessage(content=SYSTEM_PROMPT),
        HumanMessage(content=task),
    ]

    # Add conversation history
    for msg in state.get("messages", [])[-10:]:
        messages.append(msg)

    response = await model.ainvoke(messages)

    return {
        "messages": [response],
        "current_agent": "${name}",
        "output": response.content,
    }
`;

      this.addFile(`src/nodes/${name}.py`, content);
    }
  }

  private generateRouting(): string {
    return `"""
Edge routing logic for conditional transitions.
Generated by Visual Agent Builder.
"""

from __future__ import annotations

from ..state import WorkflowState


def route_after_agent(state: WorkflowState) -> str:
    """Route after an agent completes."""

    if state.get("error"):
        return "error"

    # Add custom routing logic here
    return "continue"


def should_retry(state: WorkflowState) -> str:
    """Determine if we should retry on error."""

    if state.get("retry_count", 0) >= 3:
        return "end"

    return "retry"
`;
  }

  private generatePromptFiles(): void {
    const agents = this.getNodesByType('AGENT');

    for (const agent of agents) {
      const name = this.slugify(agent.data.config?.name || agent.data.label);
      const config = agent.data.config || {};

      const systemPrompt = config.systemPrompt || `You are ${config.name || agent.data.label}, a helpful AI assistant.`;

      const content = `"""
Prompts for ${config.name || agent.data.label}.
Generated by Visual Agent Builder.
"""

SYSTEM_PROMPT = """${systemPrompt.replace(/"/g, '\\"')}"""
`;

      this.addFile(`src/prompts/${name}.py`, content);
    }
  }
}
